import os
import getpass 
import time
import google.generativeai as genai

from operator import itemgetter
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings 
from langchain_community.document_loaders import UnstructuredWordDocumentLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_core.documents import Document 

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_message_histories import ChatMessageHistory
# â­ V5.0 ä¿®æ”¹é»: "RunnableWithMessageHistory" å·²è¢«ç§»é™¤ï¼Œå› ç‚ºæˆ‘å€‘æ”¹ç‚ºæ‰‹å‹•ç®¡ç†

# -------------------------------------
# ç¬¬ 1 éƒ¨åˆ† & ç¬¬ 2 éƒ¨åˆ† (å®Œå…¨ä¸è®Š)
# -------------------------------------

if "GEMINI_API_KEY" not in os.environ:
    os.environ["GEMINI_API_KEY"] = 'AIzaSyC41yvKh5Bt7XiFN5msH82WDYxWME4_GmI' 

print("Environment setup complete. API Key loaded.")

word_file_path = "game rules and output format.docx"
print(f"Loading game rules from '{word_file_path}'...")
loader = UnstructuredWordDocumentLoader(word_file_path)
raw_documents = loader.load()
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
final_splits = text_splitter.split_documents(raw_documents)
for doc in final_splits:
    doc.metadata = {"source": "rules"}
print(f"Total text chunks for indexing: {len(final_splits)}")
print("Initializing Embedding model...")
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=os.environ["GEMINI_API_KEY"])
print("Building 'Game Rules' vector database index...")
vectorstore = Chroma.from_documents(documents=final_splits, embedding=embeddings)
print("="*30)
print("âœ… Game Rules vector database indexing complete.")
print("="*30)

# -------------------------------------
# ç¬¬ 3 éƒ¨åˆ†ï¼šå»ºç«‹ RAG éˆèˆ‡ Chat Memory (V5.0 ä¿®æ”¹)
# -------------------------------------

print("Initializing Gemini chat model...")

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", 
    google_api_key=os.environ["GEMINI_API_KEY"],
    temperature=1.0
)

rules_retriever = vectorstore.as_retriever(
    search_kwargs={"filter": {"source": "rules"}} 
)

# Prompt æ¨¡æ¿ (ä¸è®Š)
chatbot_template = ChatPromptTemplate.from_messages([
    ("system", """You are an AI player in a game of Rock-Paper-Scissors. Your goal is to win.

Here are the non-negotiable game rules and output format:
{context}

Review our entire chat history below to analyze my moves, then make your next move.
The chat history contains the full results of previous rounds.
Your final output MUST be ONE WORD: 'paper', 'stone', or 'scissors'."""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{question}")
])

# åŸºç¤ RAG éˆ (ä¸è®Š)
# é€™æ¢éˆè¨­è¨ˆç‚ºæ¥æ”¶ä¸€å€‹å­—å…¸ï¼š{"question": ..., "chat_history": ...}
base_rag_chain = (
    {
        "context": itemgetter("question") | rules_retriever,
        "question": itemgetter("question"),
        "chat_history": itemgetter("chat_history")
    }
    | chatbot_template
    | llm
    | StrOutputParser()
)

# è¨˜æ†¶é«”å„²å­˜å€ (ä¸è®Š)
chat_memory_store = {}

def get_session_history(session_id: str):
    if session_id not in chat_memory_store:
        chat_memory_store[session_id] = ChatMessageHistory()
    return chat_memory_store[session_id]

# â­ V5.0 ä¿®æ”¹é»: ç§»é™¤äº† "chain_with_memory = RunnableWithMessageHistory(...)"
# æˆ‘å€‘å°‡åœ¨è¿´åœˆä¸­ç›´æ¥å‘¼å« "base_rag_chain"

print("RAG components are ready.")

# -------------------------------------
# ç¬¬ 4 éƒ¨åˆ†ï¼šã€V5.0 é›™ç›²æ¨¡å¼ã€‘éŠæˆ²è¿´åœˆ
# -------------------------------------

print("\n" + "="*30)
print("Welcome to Double-Blind RPS! (V5.0)")
print("="*30)

round_count = 1
valid_moves = ["scissors", "stone", "paper"] 
game_outcomes = []
game_session_id = f"game_{time.time()}" 

while True:
    print(f"\n--- ROUND {round_count} ---")
    
    # â­ V5.0: åœ¨æœ¬è¼ªé–‹å§‹æ™‚ï¼Œå…ˆå–å¾—ã€Œåˆ°ä¸Šä¸€è¼ªç‚ºæ­¢ã€çš„æ­·å²
    history_object = get_session_history(game_session_id)
    previous_history_messages = history_object.messages

    # 1. æç¤ºä½¿ç”¨è€…å…ˆå‡ºæ‹³ (é‚è¼¯ä¸è®Š)
    my_move = ""
    while my_move not in valid_moves:
        my_move = input(f"Make your move ({'/'.join(valid_moves)}): ").lower() 
        if my_move not in valid_moves:
            print(f"Invalid input. Please enter one of: {', '.join(valid_moves)}")
    
    print(f"\nYou chose: {my_move}")
    
    # 2. ã€V5.0 ä¿®æ”¹é»ã€‘: æº–å‚™ "é›™ç›²" è¨Šæ¯
    # é€™å€‹æç¤ºã€æ²’æœ‰ã€‘åŒ…å« my_moveã€‚AI å¿…é ˆç›²çŒœã€‚
    game_query = "Based on our entire past game history, make your move."

    # 3. ã€V5.0 ä¿®æ”¹é»ã€‘: åŸ·è¡Œ "åŸºç¤" RAG éˆ
    print("Gemini is thinking...")
    time.sleep(1)
    
    # æˆ‘å€‘ç›´æ¥å‘¼å« base_rag_chainï¼Œä¸¦æ‰‹å‹•å‚³å…¥ã€Œä¸Šä¸€è¼ªçš„ã€æ­·å²
    gemini_choice = base_rag_chain.invoke(
        {
            "question": game_query,
            "chat_history": previous_history_messages # å‚³å…¥åˆ°ä¸Šä¸€å±€ç‚ºæ­¢çš„æ­·å²
        },
        config={"configurable": {"session_id": game_session_id}} # config ä»éœ€å‚³å…¥
    ).strip().lower()

    print(f"Gemini chose: {gemini_choice}")
    print("-" * 30)

    # 4. åˆ¤æ–·å‹è²  (é‚è¼¯ä¸è®Š)
    winner = ""
    if gemini_choice not in valid_moves:
        winner = "GAME FAILED"
        print(f"GAME FAILED! Gemini's response was '{gemini_choice}'.")
    elif my_move == gemini_choice:
        winner = "Draw"
        print("ğŸ‰ Result: It's a draw!")
    elif (my_move == "stone" and gemini_choice == "scissors") or \
         (my_move == "scissors" and gemini_choice == "paper") or \
         (my_move == "paper" and gemini_choice == "stone"):
        winner = "User"
        print("ğŸ‰ Result: Congratulations! You win!")
    else:
        winner = "AI"
        print("ğŸ˜­ Result: Oh no! You lose!")

    # 5. å‹ç‡çµ±è¨ˆ (é‚è¼¯ä¸è®Š)
    game_outcomes.append(winner)
    recent_outcomes = game_outcomes[-5:] 
    ai_wins = recent_outcomes.count("AI")
    total_recent_games = len(recent_outcomes)
    ai_win_rate = (ai_wins / total_recent_games) * 100 if total_recent_games > 0 else 0.0
    print("-" * 30)
    print(f"ğŸ“ˆ AI æœ€è¿‘ {total_recent_games} å±€å‹ç‡: {ai_win_rate:.0f}% ({ai_wins} å‹)")

    # 6. ã€V5.0 ä¿®æ”¹é»ã€‘: æ‰‹å‹•å°‡ã€Œæœ¬è¼ªçµæœã€å­˜å…¥è¨˜æ†¶é«”
    
    # é€™æ˜¯ AI ä¸‹ä¸€è¼ªæœƒçœ‹åˆ°çš„ã€Œå­¸ç¿’è³‡æ–™ã€
    result_string = f"Round {round_count} Result: I played {my_move}, you played {gemini_choice}. Winner: {winner}."
    
    # "history_object" æ˜¯æˆ‘å€‘åœ¨è¿´åœˆé–‹é ­æŠ“å–çš„é‚£å€‹
    history_object.add_user_message(game_query)      # å„²å­˜ AI çœ‹åˆ°çš„æç¤º
    history_object.add_ai_message(gemini_choice)     # å„²å­˜ AI çš„å›ç­”
    history_object.add_user_message(result_string)   # â­ å„²å­˜ã€Œæœ¬å±€çµæœã€è®“ AI å­¸ç¿’
    
    print("Chat history manually updated with round results.")

    # 7. è©¢å•æ˜¯å¦ç¹¼çºŒ (é‚è¼¯ä¸è®Š)
    round_count += 1
    play_again = input("\nPlay another round? (y/n): ").lower().strip()
    if play_again != 'y':
        print(f"\nGame over. Clearing chat history for session '{game_session_id}'.")
        print("Thank you for playing!")
        break 

print("="*30)